{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.spatial import distance\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from matplotlib import transforms\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.colors as clr\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.regularizers import *\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import metrics\n",
    "import keras.backend as K\n",
    "\n",
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "# session = tf.Session(config=config)\n",
    "# K.set_session(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_load_path = ''\n",
    "model_name = ''\n",
    "\n",
    "\n",
    "print(\"Model loaded ===\", str(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis 1. latent features - significant genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINCS gene info\n",
    "gene_annotation = pd.read_csv('./data/lincs_gene_list.csv', index_col=0)\n",
    "# TWOSIDES drug info\n",
    "ts_drug_annot = pd.read_csv('./data/twosides_drug_info.csv', index_col=0)\n",
    "# TWOSIDES predicted expression\n",
    "twosides_exp = pd.read_csv('./data/twosides_predicted_expression_scaled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/'\n",
    "train_x = pd.read_csv(data_path+'ddi_example_x.csv')\n",
    "train_y = pd.read_csv(data_path+'ddi_example_y.csv')\n",
    "print('Data loaded === ', train_x.shape, train_y.shape)\n",
    "\n",
    "train_data = pd.concat([train_x, train_y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_exp(drug_df, ts_exp, column_name):\n",
    "    return pd.merge(drug_df, ts_exp, left_on=column_name, right_on='pubchem', how='left').iloc[:,2:]\n",
    "\n",
    "def extract_expression(classification_model, train_data, drug_id, twosides_exp):\n",
    "\n",
    "    att_a = train_data[(train_data.drug1 == drug_id)&(train_data.label == 1)].drop_duplicates(subset=['drug1','drug2'])\n",
    "    att_b = train_data[(train_data.drug2 == drug_id)&(train_data.label == 1)].drop_duplicates(subset=['drug1','drug2'])\n",
    "    \n",
    "    # drug pair(a,b) & drug pair(b,a)\n",
    "    att_b2 = att_b[['drug2','drug1','SE','label']]\n",
    "    att_b2.columns = ['drug1','drug2','SE','label']\n",
    "    \n",
    "    att_drug_pair = pd.concat([att_a, att_b2], axis=0, ignore_index=True)\n",
    "    \n",
    "    # input\n",
    "    drug1 = find_exp(att_drug_pair[['drug1']], twosides_exp, 'drug1')\n",
    "    drug2 = find_exp(att_drug_pair[['drug2']], twosides_exp, 'drug2')\n",
    "    drug_se = att_drug_pair['SE']\n",
    "    print('Data shape: ', drug1.shape, drug2.shape, drug_se.shape)\n",
    "\n",
    "    attention_layer = K.function([classification_model.layers[0].input, classification_model.layers[1].input, classification_model.layers[6].input],[classification_model.layers[7].output])\n",
    "    attention_d1 = K.function([classification_model.layers[0].input, classification_model.layers[1].input, classification_model.layers[6].input],[classification_model.layers[4].output])\n",
    "    attention_layer2 = K.function([classification_model.layers[0].input, classification_model.layers[1].input, classification_model.layers[6].input],[classification_model.layers[8].output])\n",
    "    attention_d2 = K.function([classification_model.layers[0].input, classification_model.layers[1].input, classification_model.layers[6].input],[classification_model.layers[5].output])\n",
    "\n",
    "    attention_vector = attention_layer([drug1, drug2, drug_se])[0]\n",
    "    attention_vector2 = attention_layer2([drug1, drug2, drug_se])[0]\n",
    "    d1_vector = attention_d1([drug1, drug2, drug_se])[0]\n",
    "    d2_vector = attention_d2([drug1, drug2, drug_se])[0]\n",
    "\n",
    "    se_list_gb_a = pd.DataFrame(pd.merge(att_a[['drug1','drug2']], train_data, on=['drug1','drug2'], how='left').groupby(['drug1','drug2'])['SE'].apply(list))\n",
    "    se_list_gb_b = pd.DataFrame(pd.merge(att_b[['drug1','drug2']], train_data, on=['drug1','drug2'], how='left').groupby(['drug1','drug2'])['SE'].apply(list))\n",
    "    \n",
    "    se_list_gb = pd.concat([se_list_gb_a, se_list_gb_b], axis=0)\n",
    "    \n",
    "    print(se_list_gb.shape)\n",
    "    se_binary = pd.DataFrame(np.zeros((se_list_gb.shape[0], 963)), columns=[x for x in range(0,963)], index=se_list_gb.index)\n",
    "    for index, row in se_list_gb.iterrows():\n",
    "        se_binary.loc[index,row.SE] = 1\n",
    "    print('Corresponding side effects : ', se_binary.shape)    \n",
    "    \n",
    "    return att_drug_pair, attention_vector, attention_vector2, drug1, d1_vector, se_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "#    Extract weighted genes (Top 100)\n",
    "#    convert index to corresponding gene IDs\n",
    "###################################\n",
    "\n",
    "def extract_top100genes(ddi_pair, gene_header):\n",
    "    index_to_geneID = {k:v[0] for k,v in zip(gene_header.index, gene_header.values)}\n",
    "\n",
    "    temp = pd.DataFrame(ddi_pair, columns=gene_header.values.flatten().tolist())\n",
    "    top_100_gene = pd.DataFrame({col: temp.abs().T[col].nlargest(100).index.tolist() for n, col in enumerate(temp.T)}).T\n",
    "\n",
    "    return top_100_gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_pair_subset, att_mat1, att_mat2, input_d1_mat, d1_att_mat, se_binary = extract_expression(classification_model, train_data, 3310, twosides_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drug1_sig_genes = extract_top100genes(att_mat1, gene_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###################################\n",
    "#    Heatmap of changed features\n",
    "###################################\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "temp = pd.DataFrame(d1_att_mat)\n",
    "temp = temp.fillna(0)\n",
    "\n",
    "# Clustermap\n",
    "cg = sns.clustermap(temp, metric='correlation', figsize=(18,10), row_cluster=True, col_cluster=True, \\\n",
    "               cmap='seismic', vmin=-2, vmax=2, center=0, xticklabels=False, yticklabels=False)\n",
    "\n",
    "\n",
    "hm_ax = cg.ax_heatmap\n",
    "hm_ax.add_patch(Rectangle((0,0), 978,temp.shape[0], fill=False, edgecolor='grey', lw=3))\n",
    "cg.ax_col_dendrogram.set_visible(False)\n",
    "\n",
    "ax = cg.fig.add_axes([hm.x0 + hm.width+0.01, hm.y0, 0.01, hm.height])\n",
    "den_row = cg.ax_row_dendrogram.get_position()\n",
    "cg.ax_row_dendrogram.set_position([den_row.x0, den_row.y0, den_row.width*0.5, den_row.height])\n",
    "cg.ax_heatmap.set_position([hm.x0 - den_row.width*0.5, hm.y0, hm.width+den_row.width*0.5, hm.height])\n",
    "\n",
    "# Clustering\n",
    "cluster_number = fcluster(cg.dendrogram_row.linkage, t=5, criterion='maxclust')[cg.dendrogram_row.reordered_ind]\n",
    "cluster_number = cluster_number.reshape(cluster_number.shape[0], 1)\n",
    "\n",
    "sns.heatmap(cluster_number,cmap=sns.color_palette('Accent_r', 10), cbar=False, xticklabels=False, yticklabels=False, ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis 2. side effects of each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of occurrence (drug pairs) of each side effect\n",
    "se_occur = pd.read_csv('./data/twosides_side_effects_occurrence.csv')\n",
    "\n",
    "# TWOSIDES side effect info\n",
    "se_info = pd.read_csv('./data/twosides_side_effect_info.csv', index_col=0)\n",
    "se_name_dict = dict(zip(se_info.SE_map, se_info['Side Effect Name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert order based on clustering results from the heatmap\n",
    "order = drug_pair_subset.reset_index(drop=True).loc[cg.dendrogram_row.reordered_ind][['drug1','drug2']]\n",
    "se_ordered = pd.merge(order, se_binary.reset_index(), on=['drug1','drug2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nCk(n, k):\n",
    "    \"\"\"\n",
    "    A fast way to calculate binomial coefficients by Andrew Dalke (contrib).\n",
    "    \"\"\"\n",
    "    if 0 <= k <= n:\n",
    "        ntok = 1\n",
    "        ktok = 1\n",
    "        for t in range(1, min(k, n - k) + 1):\n",
    "            ntok *= n\n",
    "            ktok *= t\n",
    "            n -= 1\n",
    "        return ntok // ktok\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def hypergeometricTest(N, n, K, k):\n",
    "    odds_ratio = (k/K) / (n/N)\n",
    "    p_value = (nCk(K,k)*nCk(N-K, n-k)) / nCk(N,n)\n",
    "    \n",
    "    return p_value, odds_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count #side effects, #drugs for each cluster\n",
    "num_pairs_per_cluster = pd.concat([se_ordered.iloc[:,2:], pd.DataFrame(cluster_number, columns=['ClusterNum'])], axis=1).groupby(['ClusterNum']).count()\n",
    "num_se_per_cluster = pd.concat([se_ordered.iloc[:,2:], pd.DataFrame(cluster_number, columns=['ClusterNum'])], axis=1).groupby(['ClusterNum']).sum()\n",
    "\n",
    "\n",
    "#############################################\n",
    "#    Frequent side effects of each cluster\n",
    "#############################################\n",
    "se_freq_63460 = se_occur['num_occur'].to_dict()\n",
    "\n",
    "se_freq_rank = pd.DataFrame(columns=[x for x in range(0,963)])\n",
    "se_freq_rank_pvalue = pd.DataFrame(columns=[x for x in range(0,963)])\n",
    "\n",
    "for index, row in num_pairs_per_cluster.iterrows():\n",
    "    se_odds = dict()\n",
    "    se_pvalue = dict()\n",
    "    for key,value in dict(row).items():\n",
    "        N = 63460\n",
    "        n = int(se_freq_63460[key])\n",
    "        K = value\n",
    "        k = int(num_se_per_cluster.loc[index,key])\n",
    "\n",
    "        p_value, odds_ratio = hypergeometricTest(N,n,K,k)\n",
    "        \n",
    "        se_odds[key] = odds_ratio\n",
    "        se_pvalue[key] = p_value\n",
    "        \n",
    "    \n",
    "    odds_df = pd.DataFrame(se_odds, index=[index])\n",
    "    se_freq_rank = pd.concat([se_freq_rank, odds_df], axis=0)\n",
    "    \n",
    "    pvalue_df = pd.DataFrame(se_pvalue, index=[index])\n",
    "    se_freq_rank_pvalue = pd.concat([se_freq_rank_pvalue, pvalue_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "#    TOP frequent side effects of each cluster (side effect names)\n",
    "#######################################################################\n",
    "topSE_cluster = pd.DataFrame({col: se_freq_rank.T[col].nlargest(5).index.tolist() for n, col in enumerate(se_freq_rank.T)}).T\n",
    "topSE_cluster.replace(se_name_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
