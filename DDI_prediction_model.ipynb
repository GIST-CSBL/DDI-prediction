{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.regularizers import *\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import metrics\n",
    "\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.python.keras.backend import set_session\n",
    "import math\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_exp(drug_df, ts_exp, column_name):\n",
    "    return pd.merge(drug_df, ts_exp, left_on=column_name, right_on='pubchem', how='left').iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "#    Data generator\n",
    "###################################\n",
    "\n",
    "class custom_dataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, x_set, y_label, batch_size, exp_df, shuffle=True):\n",
    "        self.x = x_set\n",
    "        self.y = y_label\n",
    "        self.batch_size = batch_size\n",
    "        self.indexes = np.arange(len(self.x))\n",
    "        self.shuffle = shuffle\n",
    "        self.exp_df = exp_df\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.x)/self.batch_size)\n",
    "        \n",
    "    def __data_generation__(self, x_list):\n",
    "        x1 = find_exp(x_list[['drug1']], self.exp_df, 'drug1')\n",
    "        x2 = find_exp(x_list[['drug2']], self.exp_df, 'drug2')\n",
    "        x_se = x_list['SE']\n",
    "        \n",
    "        x_se_one_hot = to_categorical(x_list['SE'], num_classes=963)\n",
    "\n",
    "        x1 = np.array(x1).astype(float)\n",
    "        x2 = np.array(x2).astype(float)\n",
    "        \n",
    "        return x1, x2, x_se, x_se_one_hot\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        indexes = self.indexes[idx*self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_x = self.x.iloc[indexes]\n",
    "        batch_y = self.y[indexes]        \n",
    "        \n",
    "        x1, x2, x_se, x_se_one_hot = self.__data_generation__(batch_x)\n",
    "        \n",
    "        return [x1, x2, x_se, x_se_one_hot], batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "#    Classification model architecture\n",
    "###################################\n",
    "\n",
    "def gen_classification_model(input_drug_dim, input_se_dim, drug_emb_dim, se_emb_dim, output_dim, margin):    \n",
    "    # classification model\n",
    "    drug1_exp = Input(shape=(input_drug_dim,))\n",
    "    drug2_exp = Input(shape=(input_drug_dim,))\n",
    "    \n",
    "    hidden_d1 = Dense(output_dim=input_drug_dim)(drug1_exp)\n",
    "    hidden_d1 = BatchNormalization()(hidden_d1)\n",
    "    hidden_d2 = Dense(output_dim=input_drug_dim)(drug2_exp)\n",
    "    hidden_d2 = BatchNormalization()(hidden_d2)\n",
    "    \n",
    "    concat = Concatenate()([hidden_d1, hidden_d2])\n",
    "    \n",
    "    glu1 = Dense(input_drug_dim, activation='sigmoid')(concat)\n",
    "    glu2 = Dense(input_drug_dim, activation='sigmoid')(concat)\n",
    "    \n",
    "    att_d1 = Multiply()([hidden_d1, glu1])\n",
    "    att_d2 = Multiply()([hidden_d2, glu2])\n",
    "    \n",
    "    att_d1 = BatchNormalization()(att_d1)\n",
    "    att_d2 = BatchNormalization()(att_d2)\n",
    "\n",
    "    \n",
    "    # drug embedding\n",
    "    drug1_emb = Dense(drug_emb_dim, kernel_regularizer=l2(0.001))(att_d1)\n",
    "    drug2_emb = Dense(drug_emb_dim, kernel_regularizer=l2(0.001))(att_d2)\n",
    "    \n",
    "    # side effect\n",
    "    input_se = Input(shape=(input_se_dim,))\n",
    "    se_emb = Embedding(963, output_dim=se_emb_dim, input_length=input_se_dim)(input_se)\n",
    "\n",
    "    # one-hot side effect for metric\n",
    "    input_se_one_hot = Input(shape=(963,))\n",
    "    \n",
    "    # side effect mapping matrix\n",
    "    se_head = Embedding(963, output_dim=drug_emb_dim*se_emb_dim, input_length=input_se_dim, embeddings_regularizer=l2(0.01))(input_se)\n",
    "    se_head = Reshape((se_emb_dim, drug_emb_dim))(se_head)\n",
    "    se_tail = Embedding(963, output_dim=drug_emb_dim*se_emb_dim, input_length=input_se_dim, embeddings_regularizer=l2(0.01))(input_se)\n",
    "    se_tail = Reshape((se_emb_dim, drug_emb_dim))(se_tail)\n",
    "    \n",
    "    print(drug1_emb.shape, se_head.shape)\n",
    "    \n",
    "    # MhH & MtT\n",
    "    mh_dx = Dot(axes=(2,1))([se_head, drug1_emb])\n",
    "    mt_dy = Dot(axes=(2,1))([se_tail, drug2_emb])\n",
    "    mh_dy = Dot(axes=(2,1))([se_head, drug2_emb])\n",
    "    mt_dx = Dot(axes=(2,1))([se_tail, drug1_emb])\n",
    "    \n",
    "    # || MhH + r - MtT ||\n",
    "    score1 = add([mh_dx, se_emb])\n",
    "    score1 = subtract([score1, mt_dy])\n",
    "    score1 = Lambda(lambda x:K.sqrt(K.sum(K.square(x), axis=-1)))(score1)\n",
    "    score1 = Reshape((1,))(score1)\n",
    "    \n",
    "    score2 = add([mh_dy, se_emb])\n",
    "    score2 = subtract([score2, mt_dx])\n",
    "    score2 = Lambda(lambda x:K.sqrt(K.sum(K.square(x), axis=-1)))(score2)\n",
    "    score2 = Reshape((1,))(score2)\n",
    "    \n",
    "    final_score = add([score1, score2])\n",
    "\n",
    "    model_classification = Model(inputs=[drug1_exp, drug2_exp, input_se, input_se_one_hot], outputs=final_score)\n",
    "    model_classification.compile(loss=[lambda y_true, y_pred: custom_margin_loss(y_true, y_pred, se_one_hot=input_se_one_hot,margin=margin)], \\\n",
    "                                 optimizer=Adam(0.001), metrics=['accuracy'])\n",
    "    \n",
    "    return model_classification\n",
    "\n",
    "def custom_margin_loss(y_true, y_pred, se_one_hot, margin):\n",
    "    pos_score = (y_true*y_pred)\n",
    "    neg_score = (K.abs(K.ones_like(y_true)-y_true)*y_pred)\n",
    "    \n",
    "    se_pos = K.dot(K.transpose(pos_score), se_one_hot)\n",
    "    se_neg = K.dot(K.transpose(neg_score), se_one_hot)\n",
    "    \n",
    "    se_mask = K.cast(se_pos*se_neg, dtype=bool)\n",
    "    \n",
    "    se_pos_score = K.cast(se_mask, dtype='float32')*se_pos\n",
    "    se_neg_score = K.cast(se_mask, dtype='float32')*se_neg\n",
    "    \n",
    "    score = se_pos_score-se_neg_score+(K.ones_like(se_pos_score)*K.cast(se_mask, dtype='float32'))*margin\n",
    "    final_loss = K.sum(K.maximum(K.zeros_like(score),score))\n",
    "        \n",
    "    return final_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "#    Model checkpoint\n",
    "###################################\n",
    "\n",
    "model_save_path = '/home/eykim/DDI_model/'\n",
    "\n",
    "class CustomModelCheckPoint(keras.callbacks.Callback):\n",
    "    def __init__(self, save_path, model_name, init_learining_rate, decay_rate, decay_steps, \\\n",
    "                 save_best_metric='val_loss',this_max=False, **kargs):\n",
    "        super(CustomModelCheckPoint,self).__init__(**kargs)\n",
    "        self.epoch_loss = {}\n",
    "        self.epoch_val_loss = {}\n",
    "        self.save_path = save_path\n",
    "        self.model_name = model_name\n",
    "        \n",
    "        self.init_learining_rate = init_learining_rate\n",
    "        self.decay_rate = decay_rate\n",
    "        self.decay_steps = decay_steps\n",
    "        self.global_step = 0\n",
    "        \n",
    "        self.save_best_metric = save_best_metric\n",
    "        self.max = this_max\n",
    "        if this_max:\n",
    "            self.best = float('-inf')\n",
    "        else:\n",
    "            self.best = float('inf')\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        lr = float(K.get_value(self.model.optimizer.lr))\n",
    "#         print('learning rate: %.5f'%lr)\n",
    "        \n",
    "        metric_value = logs.get(self.save_best_metric)\n",
    "        if self.max:\n",
    "            if metric_value > self.best:\n",
    "                self.best = metric_value\n",
    "                self.best_model = self.model\n",
    "        else:\n",
    "            if metric_value < self.best:\n",
    "                self.best = metric_value\n",
    "                self.best_model = self.model\n",
    "                \n",
    "        self.epoch_loss[epoch] = logs.get('loss')\n",
    "        self.epoch_val_loss[epoch] = logs.get('val_loss')\n",
    "        self.best_model.save_weights(self.save_path + self.model_name + '.h5')\n",
    "        \n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        actual_lr = float(K.get_value(self.model.optimizer.lr))\n",
    "        decayed_learning_rate = actual_lr * self.decay_rate ** (epoch / self.decay_steps)\n",
    "        K.set_value(self.model.optimizer.lr, decayed_learning_rate)\n",
    "        if epoch % 10 == 0:\n",
    "            K.set_value(self.model.optimizer.lr, self.init_learining_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "#    Model evaluation\n",
    "###################################\n",
    "\n",
    "# boxplot predicted scores\n",
    "def mean_predicted_score(true_df, predicted_y):\n",
    "    test_pred_result = pd.concat([true_df.reset_index(drop=True), pd.DataFrame(predicted_y, columns=['predicted_score'])], axis=1)\n",
    "#     fig, ax = plt.subplots(figsize=(6,6))\n",
    "#     temp = test_pred_result.groupby('label')['predicted_score'].apply(list)\n",
    "#     sns.boxplot(x='label', y='predicted_score', data=test_pred_result[['label','predicted_score']])\n",
    "#     plt.show()\n",
    "    \n",
    "    return test_pred_result\n",
    "\n",
    "def Find_Optimal_Cutoff(target, predicted):\n",
    "    fpr, tpr, threshold = roc_curve(target, predicted)\n",
    "    i = np.arange(len(tpr)) \n",
    "    roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'threshold' : pd.Series(threshold, index=i)})\n",
    "    roc_t = roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n",
    "\n",
    "    return list(roc_t['threshold']) \n",
    "\n",
    "def cal_performance(predicted_scores_df):\n",
    "    uniqueSE = predicted_scores_df.SE.unique()\n",
    "\n",
    "    dfDict = {elem : pd.DataFrame for elem in uniqueSE}\n",
    "\n",
    "    for key in dfDict.keys():\n",
    "        dfDict[key] = predicted_scores_df[:][predicted_scores_df.SE == key]\n",
    "        \n",
    "    se_performance = pd.DataFrame(columns=['Side effect no.','median_pos', 'median_neg', 'optimal_thr','SN','SP','PR','AUC','AUPR'])\n",
    "    for se in uniqueSE:\n",
    "        df = dfDict[se]\n",
    "\n",
    "        med_1 = np.median(df[df.label == 1.0].predicted_score)\n",
    "        med_0 = np.median(df[df.label == 0.0].predicted_score)\n",
    "\n",
    "        temp_thr = (med_1 + med_0)/2\n",
    "        temp_y = df.predicted_score.apply(lambda x: 0 if x > temp_thr else 1)\n",
    "        tn, fp, fn, tp = confusion_matrix(df.label, temp_y).ravel()\n",
    "\n",
    "        optimal_thr = Find_Optimal_Cutoff(1-df.label, df.predicted_score)[0]\n",
    "        temp_y_opt = df.predicted_score.apply(lambda x: 0 if x > optimal_thr else 1)\n",
    "        tn, fp, fn, tp = confusion_matrix(df.label, temp_y_opt).ravel()\n",
    "\n",
    "        auc = roc_auc_score(1-df.label, df.predicted_score)\n",
    "        aupr = average_precision_score(1-df.label, df.predicted_score)\n",
    "\n",
    "        temp_df = pd.DataFrame({'Side effect no.':se, 'median_pos':med_1, 'median_neg':med_0, 'optimal_thr':optimal_thr, \\\n",
    "                                'SN':tp/(tp+fn), 'SP':tn/(tn+fp), 'PR':tp/(tp+fp), 'AUC':auc, 'AUPR':aupr}, index=[0])\n",
    "        se_performance = pd.concat([se_performance, temp_df], axis=0)\n",
    "        \n",
    "    return se_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "#    Model setting\n",
    "###################################\n",
    "\n",
    "def set_model_options(model_save_path, model_name, margin=1, embedding_size_drug=100, embedding_size_se=100, init_lr=0.0001, decay_rate=0.9, decay_steps=2):\n",
    "    checkpoint= CustomModelCheckPoint(save_path=model_save_path, model_name=model_name, \\\n",
    "                                      init_learining_rate=init_lr, decay_rate=decay_rate, decay_steps=decay_steps)\n",
    "    \n",
    "    classification_model = gen_classification_model(978, input_se_dim=1, drug_emb_dim=embedding_size_drug, se_emb_dim=embedding_size_se, \\\n",
    "                                                            output_dim=1, margin=margin)\n",
    "    \n",
    "    print(\"Classification model set\")\n",
    "    return classification_model, checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "#    Model train\n",
    "###################################\n",
    "\n",
    "def cross_validation(model, train_data, split_frac, sampling_size, callbacks, batch_size, exp_df):\n",
    "    optimal_threshold = pd.DataFrame(np.array(range(0,len(train_x.SE.unique()))), columns=['SE'])\n",
    "    \n",
    "    for n in range(sampling_size):\n",
    "        print(n+1, ' Sample =======')\n",
    "        cv_test = train_data.groupby(['SE', 'label']).apply(pd.DataFrame.sample, frac=split_frac)\n",
    "        cv_test_x = cv_test.reset_index(drop=True).iloc[:,:3]\n",
    "        cv_test_y = cv_test.reset_index(drop=True).iloc[:,-1]\n",
    "\n",
    "        cv_train_data_rest = pd.concat([train_data, cv_test]).drop_duplicates(keep=False, inplace=False)\n",
    "        cv_train_x = cv_train_data_rest.iloc[:,:3]\n",
    "        cv_train_y = cv_train_data_rest.iloc[:,3]\n",
    "        print('Cross validation train, test dataset size: ', cv_train_x.shape, cv_test_x.shape)\n",
    "\n",
    "        cv_train_gen = custom_dataGenerator(cv_train_x, cv_train_y.values, batch_size=batch_size, exp_df=exp_df)\n",
    "        cv_test_gen = custom_dataGenerator(cv_test_x, cv_test_y.values, batch_size=batch_size, exp_df=exp_df, shuffle=False) \n",
    "\n",
    "        steps_per_epoch = cv_train_x.shape[0] // batch_size // 10\n",
    "        \n",
    "        #======================================================================================================================#\n",
    "        model.fit_generator(generator=cv_train_gen, steps_per_epoch=steps_per_epoch, validation_data=cv_test_gen, \\\n",
    "                                                   epochs=10, verbose=0, shuffle=True, callbacks=[callbacks])\n",
    "        \n",
    "        cv_test_pred_y = model.predict_generator(generator=cv_test_gen)\n",
    "        \n",
    "        cv_test_prediction_scores = mean_predicted_score(cv_test, cv_test_pred_y)\n",
    "        cv_test_prediction_perf = cal_performance(cv_test_prediction_scores)\n",
    "        optimal_threshold = pd.concat([optimal_threshold, pd.DataFrame(cv_test_prediction_perf.optimal_thr).reset_index(drop=True)], axis=1)\n",
    "        \n",
    "    return model, optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "#    Labeling predicted scores & Calculate prediction performance\n",
    "###################################################################\n",
    "\n",
    "def calculate_predicted_label(predicted_score_df, mean_optimal_thr, se_col_name, threshold_col_name):\n",
    "    merged = pd.merge(predicted_score_df, mean_optimal_thr, left_on='SE', right_on=se_col_name, how='left')\n",
    "    merged['predicted_label'] = merged['predicted_score'] < merged[threshold_col_name]\n",
    "    merged.predicted_label = merged.predicted_label.map(int)\n",
    "    test_perf = merged[['drug1','drug2','SE','label','predicted_label','predicted_score']]\n",
    "    return test_perf\n",
    "\n",
    "def calculate_test_performance(predicted_scores_df):\n",
    "    uniqueSE = predicted_scores_df.SE.unique()\n",
    "\n",
    "    dfDict = {elem : pd.DataFrame for elem in uniqueSE}\n",
    "\n",
    "    for key in dfDict.keys():\n",
    "        dfDict[key] = predicted_scores_df[:][predicted_scores_df.SE == key]\n",
    "        \n",
    "    se_performance = pd.DataFrame(columns=['Side effect no.','SN','SP','PR','AUC','AUPR'])\n",
    "    for se in uniqueSE:\n",
    "        df = dfDict[se]\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(df.label, df.predicted_label).ravel()\n",
    "\n",
    "        auc = roc_auc_score(1-df.label, df.predicted_score)\n",
    "        aupr = average_precision_score(1-df.label, df.predicted_score)\n",
    "\n",
    "        temp_df = pd.DataFrame({'Side effect no.':se, \\\n",
    "                                'SN':tp/(tp+fn), 'SP':tn/(tn+fp), 'PR':tp/(tp+fp), 'AUC':auc, 'AUPR':aupr}, index=[0])\n",
    "        se_performance = pd.concat([se_performance, temp_df], axis=0)\n",
    "        \n",
    "    return se_performance\n",
    "\n",
    "def calculate_predicted_label(predicted_score_df, mean_optimal_thr, se_col_name, threshold_col_name):\n",
    "    merged = pd.merge(predicted_score_df, mean_optimal_thr, left_on='SE', right_on=se_col_name, how='left')\n",
    "    merged['predicted_label'] = merged['predicted_score'] < merged[threshold_col_name]\n",
    "    merged.predicted_label = merged.predicted_label.map(int)\n",
    "    merged['gap'] = merged['predicted_score'] - merged[threshold_col_name]\n",
    "    merged.gap = merged.gap.map(abs)\n",
    "    test_perf = merged[['drug1','drug2','SE','label','predicted_label','predicted_score','gap']]\n",
    "    return test_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "#    Model validation (Case 1)\n",
    "###################################\n",
    "\n",
    "def external_validation(model, test_x, test_y, optimal_threshold, batch_size, exp_df):\n",
    "    test_gen = custom_dataGenerator(validation_x, validation_y.values, batch_size=batch_size, exp_df=exp_df, shuffle=False)\n",
    "    pred_test = model.predict_generator(generator=test_gen)\n",
    "    \n",
    "    test_prediction_scores = mean_predicted_score(pd.concat([test_x, test_y], axis=1), pred_test)\n",
    "    test_prediction_predicted_label_df = calculate_predicted_label(test_prediction_scores, optimal_threshold, se_col_name='SE',threshold_col_name='mean_thr')\n",
    "    test_prediction_perf_df = calculate_test_performance(test_prediction_predicted_label_df)\n",
    "    \n",
    "    return test_prediction_predicted_label_df, test_prediction_perf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted expression of TWOSIDES drugs\n",
    "twosides_exp = pd.read_csv('/home/eykim/DDI_model/data/twosides_predicted_expression_scaled.csv')\n",
    "\n",
    "# load data (Case 1)\n",
    "data_path = '/home/eykim/DDI_model/data/'\n",
    "train_x = pd.read_csv(data_path+'ddi_example_x.csv')\n",
    "train_y = pd.read_csv(data_path+'ddi_example_y.csv')\n",
    "print('Data loaded === ', train_x.shape, train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data split to train & validation sets\n",
    "train_data = pd.concat([train_x, train_y], axis=1)\n",
    "validation_data = train_data.groupby(['SE', 'label']).apply(pd.DataFrame.sample, frac=0.1)\n",
    "\n",
    "validation_x = validation_data.reset_index(drop=True).iloc[:,:3]\n",
    "validation_y = validation_data.reset_index(drop=True).iloc[:,-1]\n",
    "\n",
    "train_data_rest = pd.concat([train_data, validation_data]).drop_duplicates(keep=False, inplace=False)\n",
    "\n",
    "print('Total: ', train_x.shape, 'Train: ', train_data_rest.shape[0], 'Test: ', validation_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = 'ddi_model'\n",
    "print('Model: ', model_name)\n",
    "\n",
    "classification_model, callbacks = set_model_options(model_save_path=model_save_path, model_name=model_name)\n",
    "classification_model, optimal_threshold = cross_validation(classification_model, train_data_rest, split_frac=0.1, sampling_size=10, callbacks=callbacks,batch_size=1024, exp_df=twosides_exp)\n",
    "print('Model trained === ')\n",
    "\n",
    "classification_model.save(model_save_path+'final_'+model_name+'.h5')\n",
    "print('Model saved === ')\n",
    "\n",
    "optimal_threshold['mean_thr'] = optimal_threshold.iloc[:,1:].mean(axis=1)\n",
    "optimal_threshold.to_csv(model_save_path+model_name+'_opt_threshold.csv')\n",
    "print('Optimal threshold saved === ')\n",
    "\n",
    "test_prediction_predicted_label_df, test_prediction_perf_df = external_validation(classification_model, validation_x, validation_y, optimal_threshold=optimal_threshold, batch_size=1024, exp_df=twosides_exp)\n",
    "print('Test set predicted === ')\n",
    "\n",
    "result_path = '/home/eykim/DDI_model/'\n",
    "\n",
    "test_prediction_predicted_label_df.to_csv(result_path + 'test_prediction_predicted_label_df.csv')\n",
    "test_prediction_perf_df.to_csv(result_path+'test_prediction_predicted_perf_df.csv')\n",
    "print('Test performance saved === ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
